{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjpifeWGd4mb"
      },
      "source": [
        "---\n",
        "sidebar_label: PyMuPDF4LLM\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uNNhQn4d4md"
      },
      "source": [
        "# PyMuPDF4LLMLoader\n",
        "\n",
        "This notebook provides a quick overview for getting started with PyMuPDF4LLM [document loader](https://python.langchain.com/docs/concepts/#document-loaders). For detailed documentation of all PyMuPDF4LLMLoader features and configurations head to the [GitHub repository](https://github.com/lakinduboteju/langchain-pymupdf4llm).\n",
        "\n",
        "## Overview\n",
        "\n",
        "### Integration details\n",
        "\n",
        "| Class | Package | Local | Serializable | JS support |\n",
        "| :--- | :--- | :---: | :---: |  :---: |\n",
        "| [PyMuPDF4LLMLoader](https://github.com/lakinduboteju/langchain-pymupdf4llm) | [langchain_pymupdf4llm](https://pypi.org/project/langchain-pymupdf4llm) | ✅ | ❌ | ❌ |\n",
        "\n",
        "### Loader features\n",
        "\n",
        "| Source | Document Lazy Loading | Native Async Support | Extract Images | Extract Tables |\n",
        "| :---: | :---: | :---: | :---: | :---: |\n",
        "| PyMuPDF4LLMLoader | ✅ | ❌ | ✅ | ✅ |\n",
        "\n",
        "## Setup\n",
        "\n",
        "To access PyMuPDF4LLM document loader you'll need to install the `langchain-pymupdf4llm` integration package.\n",
        "\n",
        "### Credentials\n",
        "\n",
        "No credentials are required to use PyMuPDF4LLMLoader."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJ4aB6Y_d4mf"
      },
      "source": [
        "If you want to get automated best in-class tracing of your model calls you can also set your [LangSmith](https://docs.smith.langchain.com/) API key by uncommenting below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJ4AgAYPd4mg"
      },
      "outputs": [],
      "source": [
        "# os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API key: \")\n",
        "# os.environ[\"LANGSMITH_TRACING\"] = \"true\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGlrejyud4mi"
      },
      "source": [
        "### Installation\n",
        "\n",
        "Install **langchain_community** and **langchain-pymupdf4llm**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kbJfLEgZd4mi",
        "outputId": "e8d0da02-b3e0-44df-9a4c-d0c1e4b0de83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m415.4/415.4 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install -qU langchain_community langchain-pymupdf4llm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-_hULNMd4mk"
      },
      "source": [
        "## Initialization\n",
        "\n",
        "Now we can instantiate our model object and load documents:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_zDWoXu7d4mk"
      },
      "outputs": [],
      "source": [
        "from langchain_pymupdf4llm import PyMuPDF4LLMLoader\n",
        "\n",
        "file_path = \"/content/paper_6114f3c3a8ea.pdf\"\n",
        "loader = PyMuPDF4LLMLoader(file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsUATgIsd4ml"
      },
      "source": [
        "## Load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "IGfJE4f8d4mm",
        "outputId": "b6a25cc5-a8f1-4b52-d42d-00ca1ea10856",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-12-29T02:07:31+00:00', 'source': '/content/paper_6114f3c3a8ea.pdf', 'file_path': '/content/paper_6114f3c3a8ea.pdf', 'total_pages': 12, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2023-12-29T02:07:31+00:00', 'trapped': '', 'modDate': 'D:20231229020731Z', 'creationDate': 'D:20231229020731Z', 'page': 0}, page_content='## Fast Inference of Mixture-of-Experts Language Models with Offloading\\n\\n\\n**Artyom Eliseev**\\nMoscow Institute of Physics and Technology\\nYandex School of Data Analysis\\n```\\n   lavawolfiee@gmail.com\\n\\n```\\n\\n**Denis Mazur**\\nMoscow Institute of Physics and Technology\\nYandex\\nResearchcore\\n```\\n   denismazur8@gmail.com\\n\\n```\\n\\n### Abstract\\n\\n\\nWith the widespread adoption of Large Language Models (LLMs), many deep\\nlearning practitioners are looking for strategies of running these models more\\nefficiently. One such strategy is to use sparse Mixture-of-Experts (MoE) — a\\ntype of model architectures where only a fraction of model layers are active for\\nany given input. This property allows MoE-based language models to generate\\ntokens faster than their “dense” counterparts, but it also increases model size\\ndue to having multiple “experts”. Unfortunately, this makes state-of-the-art MoE\\nlanguage models difficult to run without high-end GPUs. In this work, we study\\nthe problem of running large MoE language models on consumer hardware with\\nlimited accelerator memory. We build upon parameter offloading algorithms and\\npropose a novel strategy that accelerates offloading by taking advantage of innate\\nproperties of MoE LLMs. Using this strategy, we build can run Mixtral-8x7B with\\nmixed quantization on desktop hardware and free-tier Google Colab instances.\\n\\n### 1 Introduction\\n\\n\\nMany recent advances in natural language processing rely on large pre-trained language models, such\\nas GPT-3 and 4 Brown et al. (2020); OpenAI (2023), Palm & Gemini Chowdhery et al. (2022); Team\\net al. (2023) and many others. However, the rapid scientific progress in this area would be impossible\\nwithout open-access LLMs such as LLaMA 1 and 2 (Touvron et al., 2023), Falcon (TII UAE, 2023),\\nBLOOM (Scao et al., 2022), OPT (Zhang et al., 2022), or NeoX/Pythia (Biderman et al., 2023). The\\nkey advantage of open-access LLMs is that researchers can deploy them locally and modify them in\\nways that would be impossible with proprietary APIs.\\n\\nEven though LLM parameters are openly available, it is still difficult to use these models due to their\\nsheer size. State-of-the-art open-access language models require multiple high-end GPUs [1] even for\\nbasic inference workloads. To use these LLMs on more affordable hardware setups, one must either\\ncompress model parameters (Dettmers et al., 2022; Frantar et al., 2022) or offload parameters to a\\ncheaper storage, be it RAM or SSD (Pudipeddi et al., 2020; Sheng et al., 2023).\\n\\nSeveral recent works modify transformer architecture by introducing sparse Mixture-of-Experts\\nblocks (Jacobs et al., 1991; Shazeer et al., 2017). MoE blocks contain multiple “experts” (layers),\\nas well as a “gating function” that selects which experts are used on a given input. As a result, the\\nMoE block uses a small portion of all “experts” for any single forward pass, allowing for more\\ncompute-efficient training Fedus et al. (2021); Du et al. (2022). Notably, MoEs are among the\\nlargest Fedus et al. (2021) and among the best Mixtral AI team (2023) of available LLMs. While\\nMixture-of-Experts models can be more efficient than their dense counterparts, many techniques for\\nefficient LLM inference were not designed with MoE in mind and perform suboptimally on modern\\nlarge language models that use mixture-of-experts layers.\\n\\n1When deployed in 16-bit precision, Falcon-180B needs approximately 360GB, while LLaMA-2 70B requires\\n140GB of combined accelerator memory.\\n\\n')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "docs = loader.load()\n",
        "docs[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "sFCtsTOid4mm",
        "outputId": "2297a367-533a-4a09-9e24-ed5e5e3f3631",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'producer': 'pdfTeX-1.40.25',\n",
            " 'creator': 'LaTeX with hyperref',\n",
            " 'creationdate': '2023-12-29T02:07:31+00:00',\n",
            " 'source': '/content/paper_6114f3c3a8ea.pdf',\n",
            " 'file_path': '/content/paper_6114f3c3a8ea.pdf',\n",
            " 'total_pages': 12,\n",
            " 'format': 'PDF 1.5',\n",
            " 'title': '',\n",
            " 'author': '',\n",
            " 'subject': '',\n",
            " 'keywords': '',\n",
            " 'moddate': '2023-12-29T02:07:31+00:00',\n",
            " 'trapped': '',\n",
            " 'modDate': 'D:20231229020731Z',\n",
            " 'creationDate': 'D:20231229020731Z',\n",
            " 'page': 0}\n"
          ]
        }
      ],
      "source": [
        "import pprint\n",
        "\n",
        "pprint.pp(docs[0].metadata)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5Lpa93od4mn"
      },
      "source": [
        "## Lazy Load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "VUHuMGMEd4mo",
        "outputId": "43537360-3cd5-488c-9b14-d30a59e93db6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "pages = []\n",
        "for doc in loader.lazy_load():\n",
        "    pages.append(doc)\n",
        "    if len(pages) >= 10:\n",
        "        # do some paged operation, e.g.\n",
        "        # index.upsert(page)\n",
        "\n",
        "        pages = []\n",
        "len(pages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "T9z33Uf1d4mo",
        "outputId": "33e7221e-6a4d-484b-8b6c-e45327595d8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ",\n",
            "Wang, S., Maynez, J., Phuong, M., Tobin, T., Tacchetti, A., Trebacz, M., Robinson, K., Katariya,\n",
            "Y., Riedel, S., Bailey, P., Xiao, K., Ghelani, N., Aroyo, L., Slone, A., Houlsby, N., Xiong, X., Yang,\n",
            "Z., Gribovskaya, E., Adler, J., Wirth, M., Lee, L., Li, M., Kagohara, T., Pavagadhi, J., Bridgers, S.,\n",
            "Bortsova, A., Ghemawat, S., Ahmed, Z., Liu, T., Powell, R., Bolina, V., Iinuma, M., Zablotskaia,\n",
            "P., Besle\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ",\nWang, S., Maynez, J., Phuong, M., Tobin, T., Tacchetti, A., Trebacz, M., Robinson, K., Katariya,\nY., Riedel, S., Bailey, P., Xiao, K., Ghelani, N., Aroyo, L., Slone, A., Houlsby, N., Xiong, X., Yang,\nZ., Gribovskaya, E., Adler, J., Wirth, M., Lee, L., Li, M., Kagohara, T., Pavagadhi, J., Bridgers, S.,\nBortsova, A., Ghemawat, S., Ahmed, Z., Liu, T., Powell, R., Bolina, V., Iinuma, M., Zablotskaia,\nP., Besle"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.display import Markdown, display\n",
        "\n",
        "part = pages[0].page_content[778:1189]\n",
        "print(part)\n",
        "# Markdown rendering\n",
        "display(Markdown(part))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "CHirQKsId4mp",
        "outputId": "13c868ec-1ebd-4396-d316-448bc71cd9b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'producer': 'pdfTeX-1.40.25',\n",
            " 'creator': 'LaTeX with hyperref',\n",
            " 'creationdate': '2023-12-29T02:07:31+00:00',\n",
            " 'source': '/content/paper_6114f3c3a8ea.pdf',\n",
            " 'file_path': '/content/paper_6114f3c3a8ea.pdf',\n",
            " 'total_pages': 12,\n",
            " 'format': 'PDF 1.5',\n",
            " 'title': '',\n",
            " 'author': '',\n",
            " 'subject': '',\n",
            " 'keywords': '',\n",
            " 'moddate': '2023-12-29T02:07:31+00:00',\n",
            " 'trapped': '',\n",
            " 'modDate': 'D:20231229020731Z',\n",
            " 'creationDate': 'D:20231229020731Z',\n",
            " 'page': 10}\n"
          ]
        }
      ],
      "source": [
        "pprint.pp(pages[0].metadata)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrTco31Dd4mp"
      },
      "source": [
        "The metadata attribute contains at least the following keys:\n",
        "- source\n",
        "- page (if in mode *page*)\n",
        "- total_page\n",
        "- creationdate\n",
        "- creator\n",
        "- producer\n",
        "\n",
        "Additional metadata are specific to each parser.\n",
        "These pieces of information can be helpful (to categorize your PDFs for example)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yBylZV4d4mp"
      },
      "source": [
        "## Splitting mode & custom pages delimiter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLVE68lqd4mp"
      },
      "source": [
        "When loading the PDF file you can split it in two different ways:\n",
        "- By page\n",
        "- As a single text flow\n",
        "\n",
        "By default PyMuPDF4LLMLoader will split the PDF by page."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YO8OkBpgd4mq"
      },
      "source": [
        "### Extract the PDF by page. Each page is extracted as a langchain Document object:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "eMTy4ZOwd4mq",
        "outputId": "c77d9928-e8e5-400e-bf2e-21ecef3903c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12\n",
            "{'producer': 'pdfTeX-1.40.25',\n",
            " 'creator': 'LaTeX with hyperref',\n",
            " 'creationdate': '2023-12-29T02:07:31+00:00',\n",
            " 'source': '/content/paper_6114f3c3a8ea.pdf',\n",
            " 'file_path': '/content/paper_6114f3c3a8ea.pdf',\n",
            " 'total_pages': 12,\n",
            " 'format': 'PDF 1.5',\n",
            " 'title': '',\n",
            " 'author': '',\n",
            " 'subject': '',\n",
            " 'keywords': '',\n",
            " 'moddate': '2023-12-29T02:07:31+00:00',\n",
            " 'trapped': '',\n",
            " 'modDate': 'D:20231229020731Z',\n",
            " 'creationDate': 'D:20231229020731Z',\n",
            " 'page': 0}\n"
          ]
        }
      ],
      "source": [
        "loader = PyMuPDF4LLMLoader(\n",
        "    \"/content/paper_6114f3c3a8ea.pdf\",\n",
        "    mode=\"page\",\n",
        ")\n",
        "docs = loader.load()\n",
        "\n",
        "print(len(docs))\n",
        "pprint.pp(docs[0].metadata)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSFRTZeSd4mq"
      },
      "source": [
        "In this mode the pdf is split by pages and the resulting Documents metadata contains the `page` (page number). But in some cases we could want to process the pdf as a single text flow (so we don't cut some paragraphs in half). In this case you can use the *single* mode :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tG4_5p7Hd4mr"
      },
      "source": [
        "### Extract the whole PDF as a single langchain Document object:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "EGPVwPo7d4mr",
        "outputId": "4220ffa8-4e7b-46c6-f46e-581eda307faf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "{'producer': 'pdfTeX-1.40.25',\n",
            " 'creator': 'LaTeX with hyperref',\n",
            " 'creationdate': '2023-12-29T02:07:31+00:00',\n",
            " 'source': '/content/paper_6114f3c3a8ea.pdf',\n",
            " 'file_path': '/content/paper_6114f3c3a8ea.pdf',\n",
            " 'total_pages': 12,\n",
            " 'format': 'PDF 1.5',\n",
            " 'title': '',\n",
            " 'author': '',\n",
            " 'subject': '',\n",
            " 'keywords': '',\n",
            " 'moddate': '2023-12-29T02:07:31+00:00',\n",
            " 'trapped': '',\n",
            " 'modDate': 'D:20231229020731Z',\n",
            " 'creationDate': 'D:20231229020731Z'}\n"
          ]
        }
      ],
      "source": [
        "loader = PyMuPDF4LLMLoader(\n",
        "    \"/content/paper_6114f3c3a8ea.pdf\",\n",
        "    mode=\"single\",\n",
        ")\n",
        "docs = loader.load()\n",
        "\n",
        "print(len(docs))\n",
        "pprint.pp(docs[0].metadata)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shJ2uvVQd4mr"
      },
      "source": [
        "Logically, in this mode, the `page` (page_number) metadata disappears. Here's how to clearly identify where pages end in the text flow :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npTCPpK5d4mr"
      },
      "source": [
        "### Add a custom *pages_delimiter* to identify where are ends of pages in *single* mode:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "akSHNFcrd4mr",
        "outputId": "d7ff759b-a791-4917-8bc6-77034f0dd5b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the experts that constitute vast majority of model parameters do not fit even\n",
            "with quantization. Finally, even if we could fit the model parameters in memory, running generative\n",
            "inference requires additional memory for layer activations and past attention keys & values.\n",
            "\n",
            "### 3 Method\n",
            "\n",
            "In this work, we aim to systematically find the optimal way to inference modern Mixture-of-Experts\n",
            "LLMs on desktop or low-end cloud instances. More specifically, we focus on the task of generating\n",
            "tokens interactively, i.e. generate multiple tokens per second at batch size 1[5].\n",
            "\n",
            "The generative inference workload consists of two phases: 1) encoding the input prompt \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "the experts that constitute vast majority of model parameters do not fit even\nwith quantization. Finally, even if we could fit the model parameters in memory, running generative\ninference requires additional memory for layer activations and past attention keys & values.\n\n### 3 Method\n\nIn this work, we aim to systematically find the optimal way to inference modern Mixture-of-Experts\nLLMs on desktop or low-end cloud instances. More specifically, we focus on the task of generating\ntokens interactively, i.e. generate multiple tokens per second at batch size 1[5].\n\nThe generative inference workload consists of two phases: 1) encoding the input prompt "
          },
          "metadata": {}
        }
      ],
      "source": [
        "loader = PyMuPDF4LLMLoader(\n",
        "    \"/content/paper_6114f3c3a8ea.pdf\",\n",
        "    mode=\"single\",\n",
        "    pages_delimiter=\"\\n-------THIS IS A CUSTOM END OF PAGE-------\\n\\n\",\n",
        ")\n",
        "docs = loader.load()\n",
        "\n",
        "part = docs[0].page_content[10663:11317]\n",
        "print(part)\n",
        "display(Markdown(part))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rkGHxGyd4ms"
      },
      "source": [
        "The default `pages_delimiter` is \\n-----\\n\\n.\n",
        "But this could simply be \\n, or \\f to clearly indicate a page change, or \\<!-- PAGE BREAK --> for seamless injection in a Markdown viewer without a visual effect."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Q1dhENcd4ms"
      },
      "source": [
        "# Extract images from the PDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pelQxwYLd4ms"
      },
      "source": [
        "You can extract images from your PDFs (in text form) with a choice of three different solutions:\n",
        "- rapidOCR (lightweight Optical Character Recognition tool)\n",
        "- Tesseract (OCR tool with high precision)\n",
        "- Multimodal language model\n",
        "\n",
        "The result is inserted at the end of text of the page."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9w1kpPvd4ms"
      },
      "source": [
        "### Extract images from the PDF with rapidOCR:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "spZAQH7zd4ms",
        "outputId": "51778f86-2d06-4d1c-8f2e-29703e23fcd9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.9/14.9 MB\u001b[0m \u001b[31m91.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m969.6/969.6 kB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install -qU rapidocr-onnxruntime pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "_ITa1E1-d4mt",
        "outputId": "1e44c779-989d-4d4c-d96c-f16a3adac338",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.2** **Mixed MoE Quantization**\n",
            "\n",
            "\n",
            "Next, we test how different Quantization schemes affect MoE performance and size. We also use\n",
            "Mixtral-8x7B, but this time, we use non-instruction-tuned variant since it fits better with the available\n",
            "benchmarks. We measure WikiText2 perpliexity Merity et al. (2016), C4 perplexity Raffel et al.\n",
            "(2020), as well as 5-shot MMLU accuracy Hendrycks et al. (2021). Our objective for this section is\n",
            "to find the best trade off between size and performance for offloading with the target setups. Note\n",
            "that out of 46.7B total parameters in the Mixtral-8x7B model, the experts constitute 45.1B (96.6%).\n",
            "The rest of the model parameters are allocated to embeddings, self-attention layers, MoE gates and\n",
            "minor layers such as LayerNorm.\n",
            "\n",
            "\n",
            "**Attn** **Experts** **Model**\n",
            "**C4** **MMLU**\n",
            "**quant** **quant** **size, GB [Wiki2]**\n",
            "\n",
            "\n",
            "**Attn** **Experts** **Model**\n",
            "**C4** **MMLU**\n",
            "**quant** **quant** **size, GB [Wiki2]**\n",
            "\n",
            "\n",
            "FP16\n",
            "\n",
            "4-bit\n",
            "\n",
            "\n",
            "FP16 86.99 3.59 6.52 70.51%\n",
            "4-bit 25.82 3.67 6.58 70.3%\n",
            "3-bit 23.21 3.96 6.78 69.32%\n",
            "2-bit 19.33 4.52 7.31 66.66%\n",
            "\n",
            "FP16 85.16 3.68 6.59 —\n",
            "4-bit 23.99 3.76 6.66 69.11%\n",
            "3-bit 21.37 4.05 6.87 68.47%\n",
            "2-bit 17.54 4.61 7.42 65.58%\n",
            "\n",
            "\n",
            "3-bit\n",
            "\n",
            "2-bit\n",
            "\n",
            "\n",
            "FP16 85.08 3.99 6.90 —\n",
            "4-bit 23.92 4.06 6.97 66.54%\n",
            "3-bit 21.31 4.34 7.21 65.79%\n",
            "2-bit 17.46 4.90 7.82 61.83%\n",
            "\n",
            "FP16 84.96 4.98 7.92 —\n",
            "4-bit 23.79 5.08 8.06 59.0%\n",
            "3-bit 21.18 5.36 8.34 57.67%\n",
            "2-bit 17.30 5.97 9.11 55.26%\n",
            "\n",
            "\n",
            "Table 1: Perplexity and model size evaluation of Mixtral-8x7B with different quantization for shared\n",
            "attention (Attn quant) and experts (Experts quant) layers. For comprarison, a Mistral-7B 4-bit\n",
            "quantized model has Wiki2 perplexity 5.03, C4 perplexity 7.56 and MMLU score 61.3%. See Section\n",
            "4.2 for details. Green values correspond to the configurations we chose for full system evaluation.\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "4.2** **Mixed MoE Quantization**\n\n\nNext, we test how different Quantization schemes affect MoE performance and size. We also use\nMixtral-8x7B, but this time, we use non-instruction-tuned variant since it fits better with the available\nbenchmarks. We measure WikiText2 perpliexity Merity et al. (2016), C4 perplexity Raffel et al.\n(2020), as well as 5-shot MMLU accuracy Hendrycks et al. (2021). Our objective for this section is\nto find the best trade off between size and performance for offloading with the target setups. Note\nthat out of 46.7B total parameters in the Mixtral-8x7B model, the experts constitute 45.1B (96.6%).\nThe rest of the model parameters are allocated to embeddings, self-attention layers, MoE gates and\nminor layers such as LayerNorm.\n\n\n**Attn** **Experts** **Model**\n**C4** **MMLU**\n**quant** **quant** **size, GB [Wiki2]**\n\n\n**Attn** **Experts** **Model**\n**C4** **MMLU**\n**quant** **quant** **size, GB [Wiki2]**\n\n\nFP16\n\n4-bit\n\n\nFP16 86.99 3.59 6.52 70.51%\n4-bit 25.82 3.67 6.58 70.3%\n3-bit 23.21 3.96 6.78 69.32%\n2-bit 19.33 4.52 7.31 66.66%\n\nFP16 85.16 3.68 6.59 —\n4-bit 23.99 3.76 6.66 69.11%\n3-bit 21.37 4.05 6.87 68.47%\n2-bit 17.54 4.61 7.42 65.58%\n\n\n3-bit\n\n2-bit\n\n\nFP16 85.08 3.99 6.90 —\n4-bit 23.92 4.06 6.97 66.54%\n3-bit 21.31 4.34 7.21 65.79%\n2-bit 17.46 4.90 7.82 61.83%\n\nFP16 84.96 4.98 7.92 —\n4-bit 23.79 5.08 8.06 59.0%\n3-bit 21.18 5.36 8.34 57.67%\n2-bit 17.30 5.97 9.11 55.26%\n\n\nTable 1: Perplexity and model size evaluation of Mixtral-8x7B with different quantization for shared\nattention (Attn quant) and experts (Experts quant) layers. For comprarison, a Mistral-7B 4-bit\nquantized model has Wiki2 perplexity 5.03, C4 perplexity 7.56 and MMLU score 61.3%. See Section\n4.2 for details. Green values correspond to the configurations we chose for full system evaluation.\n\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from langchain_community.document_loaders.parsers import RapidOCRBlobParser\n",
        "\n",
        "loader = PyMuPDF4LLMLoader(\n",
        "    \"/content/paper_6114f3c3a8ea.pdf\",\n",
        "    mode=\"page\",\n",
        "    extract_images=True,\n",
        "    images_parser=RapidOCRBlobParser(),\n",
        ")\n",
        "docs = loader.load()\n",
        "\n",
        "part = docs[5].page_content[1863:]\n",
        "print(part)\n",
        "display(Markdown(part))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3odopPTd4mt"
      },
      "source": [
        "Be careful, RapidOCR is designed to work with Chinese and English, not other languages."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzXGCrX8d4mt"
      },
      "source": [
        "### Extract images from the PDF with Tesseract:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "WcTVQkK7d4mu"
      },
      "outputs": [],
      "source": [
        "%pip install -qU pytesseract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "5YxpM3WCd4mu",
        "outputId": "afd1c9e9-a332-426a-ce25-9b08fc35ab32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TesseractNotFoundError",
          "evalue": "tesseract is not installed or it's not in your PATH. See README file for more information.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytesseract/pytesseract.py\u001b[0m in \u001b[0;36mrun_tesseract\u001b[0;34m(input_filename, output_filename_base, extension, lang, config, nice, timeout)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m         \u001b[0mproc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msubprocess_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m             self._execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0m\u001b[1;32m   1027\u001b[0m                                 \u001b[0mpass_fds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session, process_group)\u001b[0m\n\u001b[1;32m   1954\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0merr_filename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1955\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1956\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'tesseract'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTesseractNotFoundError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-90d6a239259c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mimages_parser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTesseractBlobParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m )\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_content\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1863\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_pymupdf4llm/pymupdf4llm_loader.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDocument\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lazy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlazy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDocument\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_pymupdf4llm/pymupdf4llm_loader.py\u001b[0m in \u001b[0;36m_lazy_load\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m             \u001b[0mblob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBlob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy_parse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDocument\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_pymupdf4llm/pymupdf4llm_parser.py\u001b[0m in \u001b[0;36mlazy_parse\u001b[0;34m(self, blob)\u001b[0m\n\u001b[1;32m    234\u001b[0m                 \u001b[0mfull_content_md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mpage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m                     \u001b[0mall_text_md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_page_content_in_md\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mall_text_md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n-----\\n\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m                         \u001b[0mall_text_md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_text_md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_pymupdf4llm/pymupdf4llm_parser.py\u001b[0m in \u001b[0;36m_get_page_content_in_md\u001b[0;34m(self, doc, page)\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mimg_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimg_paths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0mblob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBlob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m                 \u001b[0mimage_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy_parse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_content\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m                 \u001b[0mimage_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"]\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mr\"\\\\]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                 \u001b[0mimg_md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"![{image_text}](#)\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_community/document_loaders/parsers/images.py\u001b[0m in \u001b[0;36mlazy_parse\u001b[0;34m(self, blob)\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m                 \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_analyze_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Image text: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                 yield Document(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_community/document_loaders/parsers/images.py\u001b[0m in \u001b[0;36m_analyze_image\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0;34m\"`pip install pytesseract`\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             )\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpytesseract\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"+\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlangs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytesseract/pytesseract.py\u001b[0m in \u001b[0;36mimage_to_string\u001b[0;34m(image, lang, config, nice, output_type, timeout)\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m     return {\n\u001b[0m\u001b[1;32m    487\u001b[0m         \u001b[0mOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBYTES\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrun_and_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0mOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDICT\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrun_and_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytesseract/pytesseract.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    487\u001b[0m         \u001b[0mOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBYTES\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrun_and_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0mOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDICT\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrun_and_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m         \u001b[0mOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTRING\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrun_and_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m     }[output_type]()\n\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytesseract/pytesseract.py\u001b[0m in \u001b[0;36mrun_and_get_output\u001b[0;34m(image, extension, lang, config, nice, timeout, return_bytes)\u001b[0m\n\u001b[1;32m    350\u001b[0m         }\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m         \u001b[0mrun_tesseract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m         return _read_output(\n\u001b[1;32m    354\u001b[0m             \u001b[0;34mf\"{kwargs['output_filename_base']}{extsep}{extension}\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytesseract/pytesseract.py\u001b[0m in \u001b[0;36mrun_tesseract\u001b[0;34m(input_filename, output_filename_base, extension, lang, config, nice, timeout)\u001b[0m\n\u001b[1;32m    278\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTesseractNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtimeout_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror_string\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTesseractNotFoundError\u001b[0m: tesseract is not installed or it's not in your PATH. See README file for more information."
          ]
        }
      ],
      "source": [
        "from langchain_community.document_loaders.parsers import TesseractBlobParser\n",
        "\n",
        "loader = PyMuPDF4LLMLoader(\n",
        "    \"/content/paper_6114f3c3a8ea.pdf\",\n",
        "    mode=\"page\",\n",
        "    extract_images=True,\n",
        "    images_parser=TesseractBlobParser(),\n",
        ")\n",
        "docs = loader.load()\n",
        "\n",
        "print(docs[5].page_content[1863:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RAGmcCld4mu"
      },
      "source": [
        "### Extract images from the PDF with multimodal model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vEGWaNe5d4mu",
        "outputId": "e47a1220-f394-4d99-e60b-bbaf468942c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -qU langchain_openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2R_MguAcd4mv",
        "outputId": "5f2f4894-8cbf-4e72-9450-e65fee513274"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "StU8NWmud4m6"
      },
      "outputs": [],
      "source": [
        "from getpass import getpass\n",
        "\n",
        "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"OpenAI API key =\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXFwuXYdd4m6"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders.parsers import LLMImageBlobParser\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "loader = PyMuPDF4LLMLoader(\n",
        "    \"./example_data/layout-parser-paper.pdf\",\n",
        "    mode=\"page\",\n",
        "    extract_images=True,\n",
        "    images_parser=LLMImageBlobParser(\n",
        "        model=ChatOpenAI(model=\"gpt-4o-mini\", max_tokens=1024)\n",
        "    ),\n",
        ")\n",
        "docs = loader.load()\n",
        "\n",
        "print(docs[5].page_content[1863:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FSen1QId4m7"
      },
      "source": [
        "# Extract tables from the PDF\n",
        "\n",
        "With PyMUPDF4LLM you can extract tables from your PDFs in *markdown* format :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "npp9s3yQd4m7"
      },
      "outputs": [],
      "source": [
        "loader = PyMuPDF4LLMLoader(\n",
        "    \"./example_data/layout-parser-paper.pdf\",\n",
        "    mode=\"page\",\n",
        "    # \"lines_strict\" is the default strategy and\n",
        "    # is the most accurate for tables with column and row lines,\n",
        "    # but may not work well with all documents.\n",
        "    # \"lines\" is a less strict strategy that may work better with\n",
        "    # some documents.\n",
        "    # \"text\" is the least strict strategy and may work better\n",
        "    # with documents that do not have tables with lines.\n",
        "    table_strategy=\"lines\",\n",
        ")\n",
        "docs = loader.load()\n",
        "\n",
        "part = docs[4].page_content[3210:]\n",
        "print(part)\n",
        "display(Markdown(part))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eae0KYOHd4m7"
      },
      "source": [
        "## Working with Files\n",
        "\n",
        "Many document loaders involve parsing files. The difference between such loaders usually stems from how the file is parsed, rather than how the file is loaded. For example, you can use `open` to read the binary content of either a PDF or a markdown file, but you need different parsing logic to convert that binary data into text.\n",
        "\n",
        "As a result, it can be helpful to decouple the parsing logic from the loading logic, which makes it easier to re-use a given parser regardless of how the data was loaded.\n",
        "You can use this strategy to analyze different files, with the same parsing parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gL6umlMmd4m7"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import FileSystemBlobLoader\n",
        "from langchain_community.document_loaders.generic import GenericLoader\n",
        "from langchain_pymupdf4llm import PyMuPDF4LLMParser\n",
        "\n",
        "loader = GenericLoader(\n",
        "    blob_loader=FileSystemBlobLoader(\n",
        "        path=\"./example_data/\",\n",
        "        glob=\"*.pdf\",\n",
        "    ),\n",
        "    blob_parser=PyMuPDF4LLMParser(),\n",
        ")\n",
        "docs = loader.load()\n",
        "\n",
        "part = docs[0].page_content[:562]\n",
        "print(part)\n",
        "display(Markdown(part))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lhCViH0d4m8"
      },
      "source": [
        "## API reference\n",
        "\n",
        "For detailed documentation of all PyMuPDF4LLMLoader features and configurations head to the GitHub repository: https://github.com/lakinduboteju/langchain-pymupdf4llm"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}